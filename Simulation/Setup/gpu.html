<!DOCTYPE html><html><head>
      <title>gpu</title>
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      
      <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/katex.min.css">
      
      
      
      
      
      <style>
      /**
 * prism.js Github theme based on GitHub's theme.
 * @author Sam Clarke
 */
code[class*="language-"],
pre[class*="language-"] {
  color: #333;
  background: none;
  font-family: Consolas, "Liberation Mono", Menlo, Courier, monospace;
  text-align: left;
  white-space: pre;
  word-spacing: normal;
  word-break: normal;
  word-wrap: normal;
  line-height: 1.4;

  -moz-tab-size: 8;
  -o-tab-size: 8;
  tab-size: 8;

  -webkit-hyphens: none;
  -moz-hyphens: none;
  -ms-hyphens: none;
  hyphens: none;
}

/* Code blocks */
pre[class*="language-"] {
  padding: .8em;
  overflow: auto;
  /* border: 1px solid #ddd; */
  border-radius: 3px;
  /* background: #fff; */
  background: #f5f5f5;
}

/* Inline code */
:not(pre) > code[class*="language-"] {
  padding: .1em;
  border-radius: .3em;
  white-space: normal;
  background: #f5f5f5;
}

.token.comment,
.token.blockquote {
  color: #969896;
}

.token.cdata {
  color: #183691;
}

.token.doctype,
.token.punctuation,
.token.variable,
.token.macro.property {
  color: #333;
}

.token.operator,
.token.important,
.token.keyword,
.token.rule,
.token.builtin {
  color: #a71d5d;
}

.token.string,
.token.url,
.token.regex,
.token.attr-value {
  color: #183691;
}

.token.property,
.token.number,
.token.boolean,
.token.entity,
.token.atrule,
.token.constant,
.token.symbol,
.token.command,
.token.code {
  color: #0086b3;
}

.token.tag,
.token.selector,
.token.prolog {
  color: #63a35c;
}

.token.function,
.token.namespace,
.token.pseudo-element,
.token.class,
.token.class-name,
.token.pseudo-class,
.token.id,
.token.url-reference .token.variable,
.token.attr-name {
  color: #795da3;
}

.token.entity {
  cursor: help;
}

.token.title,
.token.title .token.punctuation {
  font-weight: bold;
  color: #1d3e81;
}

.token.list {
  color: #ed6a43;
}

.token.inserted {
  background-color: #eaffea;
  color: #55a532;
}

.token.deleted {
  background-color: #ffecec;
  color: #bd2c00;
}

.token.bold {
  font-weight: bold;
}

.token.italic {
  font-style: italic;
}


/* JSON */
.language-json .token.property {
  color: #183691;
}

.language-markup .token.tag .token.punctuation {
  color: #333;
}

/* CSS */
code.language-css,
.language-css .token.function {
  color: #0086b3;
}

/* YAML */
.language-yaml .token.atrule {
  color: #63a35c;
}

code.language-yaml {
  color: #183691;
}

/* Ruby */
.language-ruby .token.function {
  color: #333;
}

/* Markdown */
.language-markdown .token.url {
  color: #795da3;
}

/* Makefile */
.language-makefile .token.symbol {
  color: #795da3;
}

.language-makefile .token.variable {
  color: #183691;
}

.language-makefile .token.builtin {
  color: #0086b3;
}

/* Bash */
.language-bash .token.keyword {
  color: #0086b3;
}

/* highlight */
pre[data-line] {
  position: relative;
  padding: 1em 0 1em 3em;
}
pre[data-line] .line-highlight-wrapper {
  position: absolute;
  top: 0;
  left: 0;
  background-color: transparent;
  display: block;
  width: 100%;
}

pre[data-line] .line-highlight {
  position: absolute;
  left: 0;
  right: 0;
  padding: inherit 0;
  margin-top: 1em;
  background: hsla(24, 20%, 50%,.08);
  background: linear-gradient(to right, hsla(24, 20%, 50%,.1) 70%, hsla(24, 20%, 50%,0));
  pointer-events: none;
  line-height: inherit;
  white-space: pre;
}

pre[data-line] .line-highlight:before, 
pre[data-line] .line-highlight[data-end]:after {
  content: attr(data-start);
  position: absolute;
  top: .4em;
  left: .6em;
  min-width: 1em;
  padding: 0 .5em;
  background-color: hsla(24, 20%, 50%,.4);
  color: hsl(24, 20%, 95%);
  font: bold 65%/1.5 sans-serif;
  text-align: center;
  vertical-align: .3em;
  border-radius: 999px;
  text-shadow: none;
  box-shadow: 0 1px white;
}

pre[data-line] .line-highlight[data-end]:after {
  content: attr(data-end);
  top: auto;
  bottom: .4em;
}html body{font-family:"Helvetica Neue",Helvetica,"Segoe UI",Arial,freesans,sans-serif;font-size:16px;line-height:1.6;color:#333;background-color:#fff;overflow:initial;box-sizing:border-box;word-wrap:break-word}html body>:first-child{margin-top:0}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{line-height:1.2;margin-top:1em;margin-bottom:16px;color:#000}html body h1{font-size:2.25em;font-weight:300;padding-bottom:.3em}html body h2{font-size:1.75em;font-weight:400;padding-bottom:.3em}html body h3{font-size:1.5em;font-weight:500}html body h4{font-size:1.25em;font-weight:600}html body h5{font-size:1.1em;font-weight:600}html body h6{font-size:1em;font-weight:600}html body h1,html body h2,html body h3,html body h4,html body h5{font-weight:600}html body h5{font-size:1em}html body h6{color:#5c5c5c}html body strong{color:#000}html body del{color:#5c5c5c}html body a:not([href]){color:inherit;text-decoration:none}html body a{color:#08c;text-decoration:none}html body a:hover{color:#00a3f5;text-decoration:none}html body img{max-width:100%}html body>p{margin-top:0;margin-bottom:16px;word-wrap:break-word}html body>ul,html body>ol{margin-bottom:16px}html body ul,html body ol{padding-left:2em}html body ul.no-list,html body ol.no-list{padding:0;list-style-type:none}html body ul ul,html body ul ol,html body ol ol,html body ol ul{margin-top:0;margin-bottom:0}html body li{margin-bottom:0}html body li.task-list-item{list-style:none}html body li>p{margin-top:0;margin-bottom:0}html body .task-list-item-checkbox{margin:0 .2em .25em -1.8em;vertical-align:middle}html body .task-list-item-checkbox:hover{cursor:pointer}html body blockquote{margin:16px 0;font-size:inherit;padding:0 15px;color:#5c5c5c;background-color:#f0f0f0;border-left:4px solid #d6d6d6}html body blockquote>:first-child{margin-top:0}html body blockquote>:last-child{margin-bottom:0}html body hr{height:4px;margin:32px 0;background-color:#d6d6d6;border:0 none}html body table{margin:10px 0 15px 0;border-collapse:collapse;border-spacing:0;display:block;width:100%;overflow:auto;word-break:normal;word-break:keep-all}html body table th{font-weight:bold;color:#000}html body table td,html body table th{border:1px solid #d6d6d6;padding:6px 13px}html body dl{padding:0}html body dl dt{padding:0;margin-top:16px;font-size:1em;font-style:italic;font-weight:bold}html body dl dd{padding:0 16px;margin-bottom:16px}html body code{font-family:Menlo,Monaco,Consolas,'Courier New',monospace;font-size:.85em !important;color:#000;background-color:#f0f0f0;border-radius:3px;padding:.2em 0}html body code::before,html body code::after{letter-spacing:-0.2em;content:"\00a0"}html body pre>code{padding:0;margin:0;font-size:.85em !important;word-break:normal;white-space:pre;background:transparent;border:0}html body .highlight{margin-bottom:16px}html body .highlight pre,html body pre{padding:1em;overflow:auto;font-size:.85em !important;line-height:1.45;border:#d6d6d6;border-radius:3px}html body .highlight pre{margin-bottom:0;word-break:normal}html body pre code,html body pre tt{display:inline;max-width:initial;padding:0;margin:0;overflow:initial;line-height:inherit;word-wrap:normal;background-color:transparent;border:0}html body pre code:before,html body pre tt:before,html body pre code:after,html body pre tt:after{content:normal}html body p,html body blockquote,html body ul,html body ol,html body dl,html body pre{margin-top:0;margin-bottom:16px}html body kbd{color:#000;border:1px solid #d6d6d6;border-bottom:2px solid #c7c7c7;padding:2px 4px;background-color:#f0f0f0;border-radius:3px}@media print{html body{background-color:#fff}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{color:#000;page-break-after:avoid}html body blockquote{color:#5c5c5c}html body pre{page-break-inside:avoid}html body table{display:table}html body img{display:block;max-width:100%;max-height:100%}html body pre,html body code{word-wrap:break-word;white-space:pre}}.markdown-preview{width:100%;height:100%;box-sizing:border-box}.markdown-preview .pagebreak,.markdown-preview .newpage{page-break-before:always}.markdown-preview pre.line-numbers{position:relative;padding-left:3.8em;counter-reset:linenumber}.markdown-preview pre.line-numbers>code{position:relative}.markdown-preview pre.line-numbers .line-numbers-rows{position:absolute;pointer-events:none;top:1em;font-size:100%;left:0;width:3em;letter-spacing:-1px;border-right:1px solid #999;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.markdown-preview pre.line-numbers .line-numbers-rows>span{pointer-events:none;display:block;counter-increment:linenumber}.markdown-preview pre.line-numbers .line-numbers-rows>span:before{content:counter(linenumber);color:#999;display:block;padding-right:.8em;text-align:right}.markdown-preview .mathjax-exps .MathJax_Display{text-align:center !important}.markdown-preview:not([for="preview"]) .code-chunk .btn-group{display:none}.markdown-preview:not([for="preview"]) .code-chunk .status{display:none}.markdown-preview:not([for="preview"]) .code-chunk .output-div{margin-bottom:16px}.markdown-preview .md-toc{padding:0}.markdown-preview .md-toc .md-toc-link-wrapper .md-toc-link{display:inline;padding:.25rem 0}.markdown-preview .md-toc .md-toc-link-wrapper .md-toc-link p,.markdown-preview .md-toc .md-toc-link-wrapper .md-toc-link div{display:inline}.markdown-preview .md-toc .md-toc-link-wrapper.highlighted .md-toc-link{font-weight:800}.scrollbar-style::-webkit-scrollbar{width:8px}.scrollbar-style::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}.scrollbar-style::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,0.66);border:4px solid rgba(150,150,150,0.66);background-clip:content-box}html body[for="html-export"]:not([data-presentation-mode]){position:relative;width:100%;height:100%;top:0;left:0;margin:0;padding:0;overflow:auto}html body[for="html-export"]:not([data-presentation-mode]) .markdown-preview{position:relative;top:0}@media screen and (min-width:914px){html body[for="html-export"]:not([data-presentation-mode]) .markdown-preview{padding:2em calc(50% - 457px + 2em)}}@media screen and (max-width:914px){html body[for="html-export"]:not([data-presentation-mode]) .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for="html-export"]:not([data-presentation-mode]) .markdown-preview{font-size:14px !important;padding:1em}}@media print{html body[for="html-export"]:not([data-presentation-mode]) #sidebar-toc-btn{display:none}}html body[for="html-export"]:not([data-presentation-mode]) #sidebar-toc-btn{position:fixed;bottom:8px;left:8px;font-size:28px;cursor:pointer;color:inherit;z-index:99;width:32px;text-align:center;opacity:.4}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] #sidebar-toc-btn{opacity:1}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc{position:fixed;top:0;left:0;width:300px;height:100%;padding:32px 0 48px 0;font-size:14px;box-shadow:0 0 4px rgba(150,150,150,0.33);box-sizing:border-box;overflow:auto;background-color:inherit}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar{width:8px}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,0.66);border:4px solid rgba(150,150,150,0.66);background-clip:content-box}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc a{text-decoration:none}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc{padding:0 16px}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper .md-toc-link{display:inline;padding:.25rem 0}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper .md-toc-link p,html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper .md-toc-link div{display:inline}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper.highlighted .md-toc-link{font-weight:800}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{left:300px;width:calc(100% -  300px);padding:2em calc(50% - 457px -  300px/2);margin:0;box-sizing:border-box}@media screen and (max-width:1274px){html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{width:100%}}html body[for="html-export"]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .markdown-preview{left:50%;transform:translateX(-50%)}html body[for="html-export"]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .md-sidebar-toc{display:none}
/* Please visit the URL below for more information: */
/*   https://shd101wyy.github.io/markdown-preview-enhanced/#/customize-css */
.markdown-preview {
  left: 0% !important;
  transform: none !important;
}
.md-sidebar-toc.md-sidebar-toc {
  padding-top: 40px;
}
.sidebar {
  width: 96px;
  background-color: moccasin;
  box-sizing: border-box;
  border: 8px solid chocolate;
}
#sidebar-toc-btn {
  bottom: unset;
  top: 8px;
}
h1 {
  position: relative;
  overflow: hidden;
  margin-top: 50px !important;
  padding: 1.5rem 2rem 1.5rem 130px;
  border: 2px solid #010079;
  border-bottom: 1px solid #eaecef;
}
h1:before {
  position: absolute;
  top: -150%;
  left: -100px;
  width: 200px;
  height: 300%;
  content: '';
  -webkit-transform: rotate(25deg);
  transform: rotate(25deg);
  background: #010079;
}
h2 {
  border-bottom: 1px solid #010079;
  padding: 1rem 2rem;
  border-left: 5px solid #010079;
  background: #0000793a;
}
h1 span {
  font-size: 40px;
  font-size: 4rem;
  position: absolute;
  z-index: 1;
  top: 0;
  left: 0;
  display: block;
  padding-top: 3px;
  padding-left: 16px;
  color: #fff;
}
h5 {
  text-align: center;
  padding: 0.5rem 0;
  margin-bottom: 0.2rem;
  border-bottom: 6px double #010079;
  color: #323232;
  font-weight: bold;
  font-size: 200%;
}
p {
  text-indent: 1em;
}
summary {
  color: #6495ed;
}
ul.index {
  color: #2d8fdd;
  border-left: solid 2px #2d8fdd;
  /*左側の線*/
  background: #f1f8ff;
  /*背景色*/
  line-height: 2;
  padding-right: 20px;
  list-style-type: none!important;
  /*ポチ消す*/
  text-align: left;
}
.header {
  position: fixed;
  width: 100%;
  left: 0;
  top: 0px;
  font-size: 12pt;
  background: #fff;
  z-index: 1000 ;
}
.fixed-table {
  background: #0000793a;
  top: 0;
  margin: 0;
  table-layout: fixed;
  width: 100%;
  overflow-y: auto;
  /* 表が長い場合、スクロールできるようにする */
  max-height: 40vh;
  /* 画面の高さを超えないようにする */
}
th {
  background-color: #eee;
  width: 20%;
}
.gnav {
  padding: 0%;
  margin: 0;
  list-style-type: none!important;
  /*ポチ消す*/
}
.index {
  width: 200px;
}
/*子階層以降共通*/
.gnav li li {
  height: 0;
  overflow: hidden;
  transition: 0.5s;
  position: relative;
  width: 100%;
}
.gnav li:hover > ul > li {
  height: 2rem;
  z-index: 20;
  font-size: 10pt;
  overflow: visible;
  width: 100%;
}
footer {
  position: relative;
  text-align: center;
  background-color: #0000793a;
  bottom: 0;
}

      </style>
    </head>
    <body for="html-export">
      <div class="mume markdown-preview  ">
      <div class="header">
  <table class="fixed-table">
    <thead>
      <tr>
        <th class="mokuji">目次</th>
        <th><details><summary> Math </summary><ul class="gnav"><li><a href="../../Math/Basic/basic.html">基礎数学編</a>
        <ul class="index">
        <li><a href="../../Math/Basic/multiplication.html">掛け算</a></li>     
        <li><a href="../../Math/Basic/trigonometric.html">三角関数</a></li>
        <li><a href="../../Math/Basic/complex.html">複素数</a></li>
        <li><a href="../../Math/Basic/calculus.html">微分・積分</a></li>
        <li><a href="../../Math/Basic/linear_algebra.html">線形代数</a></li>
        <li><a href="../../Math/Basic/statistics.html">基礎統計</a></li>
        </ul>
        </li><li><a href="../../Math/Analysis/Analysis.html">信号処理編</a><ul class="index">
        <li><a href="../../Math/Analysis/fourier.html">フーリエ変換</a></li>
        <li><a href="../../Math/Analysis/wavelet.html">wavelet変換</a></li>
        <li><a href="../../Math/Analysis/hilbert.html">ヒルベルト変換</a></li>
        <li><a href="../../Math/Analysis/eeg.html">基本の脳波解析</a></li> <li><a href="../../Math/Analysis/phase_analysis.html">位相同期解析</a></li>
        </ul>
        </li><li><a href="../../Math/Statistics/Statistics.html">統計編</a><ul class="index">
        <li><a href="../../Math/Statistics/distribution.html">確率分布</a></li>
        <li><a href="../../Math/Statistics/central_limit_theorem.html">大数の法則と中心極限定理</a></li>
        <li><a href="../../Math/Statistics/statistic.html">統計量と標本分布</a></li>                                                         <li><a href="../../Math/Statistics/test.html">統計的検定</a></li>
        <li><a href="../../Math/Statistics/anova.html">分散分析</a></li>  
        </ul>
        </li><li><a href="../../Math/Others/Others.html">その他</a><ul class="index">
        <li><a href="../../Math/Others/ICA.html">独立成分分析</a></li> 
        <li><a href="../../Math/Others/CCA.html">正準相関分析</a></li>
        <li><a href="../../Math/Others/lagrange.html">ラグランジュの未定乗数法</a></li>
        <li><a href="../../Math/Others/Entropy.html">エントロピーと分布間距離</a></li>
        <li><a href="../../Math/Others/signal_detection.html">信号検出理論</a></li>
        </ul>
        </li></ul></details></th>
        <th><details><summary> Analysis </summary><ul class="gnav"><li><a href="../../Analysis/eeglab/eeglab.html">EEGLAB</a>
        <ul class="index">                                             <li><a href="../../Analysis/eeglab/setup.html">環境構築</a></li>
        <li><a href="../../Analysis/eeglab/import.html">データのインポート</a></li>
        <li><a href="../../Analysis/eeglab/prepro1.html">基本的な下処理</a></li>
        <li><a href="../../Analysis/eeglab/prepro2.html">発展的な下処理</a></li>
        <li><a href="../../Analysis/eeglab/analysis1.html">単被験者での解析</a></li>
        <li><a href="../../Analysis/eeglab/analysis2.html">被験者群での解析</a></li>
        </ul>
        </li><li><a href="../../Analysis/MNE/MNE.html">MNE-python</a>
        <ul class="index">
        <li><a href="../../Analysis/MNE/import.html">データのロード</a></li>
        <li><a href="../../Analysis/MNE/preprocessing.html">前処理</a></li>
        </ul> </li></ul></details></th>
        <th><details><summary> Experiment </summary><ul class="gnav">       </ul> </details></th>
        <th><details><summary> Simulations </summary><ul class="gnav">
        <li><a href="../../Simulation/Simulation.html">環境構築</a><ul class="index">
        <li><a href="../../Simulation/Setup/environment.html">Python環境構築</a></li>
        <li><a href="../../Simulation/Setup/gpu.html">pythonでのGPUセットアップ</a></li>
        <li><a href="../../Simulation/Setup/jupyter.html">Jupyterセットアップ</a></li>
        <li><a href="../../Simulation/Setup/julia.html">Juliaセットアップ</a></li>
        </ul>
        </li><li><a href="../../Simulation/NonlinearDynamics/Nonlinear-dynamics.html">非線形力学</a><ul class="index">
        <li><a href="../../Simulation/NonlinearDynamics/dynamics.html">力学系とは</a></li>
        <li><a href="../../Simulation/NonlinearDynamics/stability.html">線形安定性解析</a></li>
        <li><a href="../../Simulation/NonlinearDynamics/stability_nonlinear.html">非線形系の安定性解析</a></li>
        </ul>
        </li></ul></details></th>
      </tr>
    </thead>
  </table>
</div>
<h1><span>02</span>CuPyを使ったGPU演算</h1>
<p>ニューラルネットを実装し，テストをするためには莫大な計算量が必要になります．この全てをCPUにやらせるのは骨が折れるため，GPUを使ったPythonプログラミングのためにCuPyの勉強をしていきます．</p>
<div class="code-chunk" data-id="code-chunk-id-0" data-cmd="toc"><div class="input-div"><div class="btn-group"><div class="run-btn btn"><span>▶︎</span></div><div class="run-all-btn btn">all</div></div><div class="status">running...</div></div><div class="output-div"></div></div><ul>
<li><a href="#gpu%E3%81%A8%E3%81%AF">GPUとは</a>
<ul>
<li><a href="#cpu%E3%81%A8%E3%81%AE%E9%81%95%E3%81%84">CPUとの違い</a>
<ul>
<li><a href="#%E5%BD%B9%E5%89%B2">役割</a></li>
<li><a href="#%E5%BE%97%E6%84%8F%E3%81%A8%E3%81%99%E3%82%8B%E6%BC%94%E7%AE%97%E5%87%A6%E7%90%86">得意とする演算処理</a></li>
<li><a href="#%E3%82%B3%E3%82%A2%E6%95%B0">コア数</a></li>
<li><a href="#%E5%AE%9F%E8%A1%8C%E6%99%82%E9%96%93">実行時間</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#cuda">CUDA</a></li>
<li><a href="#cupy">CuPy</a>
<ul>
<li><a href="#cupy%E3%81%A8%E3%81%AF">CuPyとは</a></li>
<li><a href="#cupy%E3%81%AB%E3%82%88%E3%82%8Bnumpy%E3%81%AE%E4%BA%92%E6%8F%9B%E3%83%97%E3%83%AD%E3%82%B0%E3%83%A9%E3%83%A0">CuPyによるNumPyの互換プログラム</a></li>
</ul>
</li>
<li><a href="#cupyelementwisekernel">CuPy.ElementwiseKernel</a>
<ul>
<li><a href="#%E9%85%8D%E5%88%97%E3%81%AEindexing">配列のindexing</a></li>
</ul>
</li>
<li><a href="#ojas-hebbian-rule%E3%81%AE%E5%AE%9F%E8%A3%85">Oja's hebbian ruleの実装</a>
<ul>
<li><a href="#%E7%A2%BA%E8%AA%8D">確認</a></li>
<li><a href="#%E9%80%9F%E5%BA%A6%E6%AF%94%E8%BC%83">速度比較</a></li>
</ul>
</li>
</ul>
<h2 class="mume-header" id="gpu%E3%81%A8%E3%81%AF">GPUとは</h2>

<p>GPUとは，Graphics Processing Unitの略で，リアルタイム画像処理に特化した演算装置です．例えば，3Dのゲームなどでは，ぬるぬる動く映像表現を実現するために膨大な演算が必要になります．これを担当するために使われるもので，定期的に並列な演算処理を行うことを得意とします．</p>
<center><img src="../../Simulation/figures/game.jpg"></center>
<p>上の画像のようなリアルな映像を，リアルタイムに更新していくためには常に尋常じゃない規模の計算を行う必要があります．そのため，現在のGPUの多くは高速でポリゴンの移動や回転，行列演算を行い，座標の変換やフィルタ...と様々な演算が可能なように進化しています．</p>
<p>最近では，GPUが多数のデータに対して並列的に(単純な)数値計算をくり返し適用可能であることに着目して，データサイエンスなどに利用するGPGPUと呼ばれるものも登場しています．これを利用することにより，CPU(通常，コンピュータが演算処理に使うもの)ベースで動くコンピュータより遥かに早く計算をさせることが可能なため，ニューラルネットの実装には欠かせない技術になります．</p>
<h3 class="mume-header" id="cpu%E3%81%A8%E3%81%AE%E9%81%95%E3%81%84">CPUとの違い</h3>

<p>CPU(Central Processing unit)とは，コンピュータの中枢を担う演算装置で，大脳のようなものです．PCでプログラムを実行する際にも，特に特別なことをしない限りは演算は全てCPUによって行われます．GPUがグラフィックに特化して仕事をしているのに対し，CPUはコンピュータ全体の処理を担当します．HDDやOS，キーボードやマウスなど，ありとあらゆるところから送られてくる情報をまとめて処理するものです．</p>
<p>そんな大役を担うCPUなので，当然計算性能はすさまじく高く，複雑な処理が得意です．しかしその一方，複雑な計算に耐えるように設計されているので単純な計算だろうと堅実に，順番に取り組むので，時間がかかってしまう傾向があります．コアと呼ばれる実行単位のようなものも少ないため，大量に計算を投げつけられるのが苦手です．</p>
<p>以下，CPUとGPUの違いを確認してみます．</p>
<h4 class="mume-header" id="%E5%BD%B9%E5%89%B2">役割</h4>

<ul>
<li>CPU ... 全ての演算処理</li>
<li>GPU ... グラフィック専門</li>
</ul>
<h4 class="mume-header" id="%E5%BE%97%E6%84%8F%E3%81%A8%E3%81%99%E3%82%8B%E6%BC%94%E7%AE%97%E5%87%A6%E7%90%86">得意とする演算処理</h4>

<ul>
<li>CPU ... 連続的で複雑な演算処理</li>
<li>GPU ... 並列的な単純な演算処理</li>
</ul>
<h4 class="mume-header" id="%E3%82%B3%E3%82%A2%E6%95%B0">コア数</h4>

<ul>
<li>CPU ... 数個程度</li>
<li>GPU ... 数千個</li>
</ul>
<h4 class="mume-header" id="%E5%AE%9F%E8%A1%8C%E6%99%82%E9%96%93">実行時間</h4>

<ul>
<li>CPU ... 大規模な計算を投げられると遅い</li>
<li>GPU ... CPUの数倍から100倍以上の速度も可能．ただしコア1つだとCPUに遥かに劣る．人海戦術が強み．</li>
</ul>
<p>と，このように大規模なニューラルネットを実装使用と思った時も，CPUよりGPUの方が計算に向いていることが分かります．ニューラルネットの各ニューロンで行われる計算は一つ一つは大した事ありませんが，それが何百個も集まり，さらに多層になりと，計算量が増えていくにつれてGPUのありがたみが生きてきます．</p>
<h2 class="mume-header" id="cuda">CUDA</h2>

<p>そんなGPUですが，製造の大手企業に<a href="https://www.nvidia.com/ja-jp/">NVIDIA</a>社があります．NVIDIAは，自社製のGPUを使って汎用の演算処理を行うための実行環境として，CUDAを提供しています．</p>
<p>自分の環境で，本来ならCPUが行うはずの計算をGPUに投げて肩代わりしてもらうためには，これが必要になります．導入方法については<a href="environment.html">環境構築</a>にて説明しました．</p>
<p>更に，このCUDAをPythonから呼び出す方法としてCuPyを導入していました．<br>
<img src="../figures/cupy.png"></p>
<p>Pythonでやる時には，基本的にはこのCuPyの使い方をマスターすれば良いわけですが，そもそもCuPyを使うためにCUDAの知識が多少必要になるっぽいので確認していきます．</p>
<p>ここではまずCUDAについて理解するために直接いじってみます．CUDAプログラミングは，C言語ベースになっているようです．あまり慣れていないので面倒だけど，行列の積を解く問題を考えます．参考は<a href="https://www.gsic.titech.ac.jp/supercon/main/attwiki/index.php?plugin=attach&amp;refer=SupercomputingContest2016&amp;openfile=gpu-prog16-1ow.pdf">こちら</a>．</p>
<center><img src="../figures/gyoretuseki.png"></center>
<p>画像のような問題は，C言語だと以下のようになります．</p>
<pre data-role="codeBlock" data-info="C" class="language-c"><span class="token keyword keyword-for">for</span> <span class="token punctuation">(</span>i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> n<span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span> <span class="token comment">// i行目，</span>
    <span class="token keyword keyword-for">for</span> <span class="token punctuation">(</span>j <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> j <span class="token operator">&lt;</span> n<span class="token punctuation">;</span> j<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span> <span class="token comment">// 第j列に注目</span>
        <span class="token keyword keyword-for">for</span> <span class="token punctuation">(</span>k <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> k <span class="token operator">&lt;</span> n<span class="token punctuation">;</span> k<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span> <span class="token comment">// 次元数分，下の計算をやる</span>
            c<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span> <span class="token operator">+=</span> a<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>k<span class="token punctuation">]</span><span class="token operator">*</span>b<span class="token punctuation">[</span>k<span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">;</span> <span class="token comment">// cijはaikとbkjの積</span>
        <span class="token punctuation">}</span> <span class="token punctuation">}</span> <span class="token punctuation">}</span>
</pre><p>この計算を，CPUに行わせると，次元数に応じてかなり大きな回数の計算を行うことになるため，時間がかかってしまいます．ここでGPUの出番です．GPUは，性能は低いけども計算が可能な演算装置，コアがたくさんいます．こいつらにそれぞれ，自分の担当の<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>C</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow><annotation encoding="application/x-tex">C_{ij}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">ij</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span></p>
<pre data-role="codeBlock" data-info="C" class="language-c"><span class="token keyword keyword-for">for</span> <span class="token punctuation">(</span>k <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> k <span class="token operator">&lt;</span> n<span class="token punctuation">;</span> k<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span> <span class="token comment">// 次元数分，下の計算をやる</span>
        c<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span> <span class="token operator">+=</span> a<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>k<span class="token punctuation">]</span><span class="token operator">*</span>b<span class="token punctuation">[</span>k<span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">;</span> <span class="token comment">// cijはaikとbkjの積</span>
<span class="token punctuation">}</span>
</pre><p>を割り振って計算してもらえば，一つ一つのコアがやる計算はとても少なくなるため，超高速化が可能になるわけです．CUDAではこの際，分担してくれるコア達のことをスレッドと呼ぶようです．</p>
<p>では実際，そのような分担はどうやってやらせるのでしょうか．答えを確認すると以下のようになるようです．</p>
<details><summary>プログラム全体</summary>
<pre data-role="codeBlock" data-info="C" class="language-c"><span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">include</span> <span class="token string">&lt;stdio.h&gt;</span></span>
<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">include</span> <span class="token string">&lt;stdlib.h&gt;</span></span>

__global__ <span class="token keyword keyword-void">void</span> <span class="token function">mm_gpu</span><span class="token punctuation">(</span><span class="token keyword keyword-double">double</span> <span class="token operator">*</span>A<span class="token punctuation">,</span> <span class="token keyword keyword-double">double</span> <span class="token operator">*</span>B<span class="token punctuation">,</span> <span class="token keyword keyword-double">double</span> <span class="token operator">*</span>C<span class="token punctuation">,</span> <span class="token keyword keyword-int">int</span> n<span class="token punctuation">)</span>
<span class="token punctuation">{</span>
    <span class="token keyword keyword-int">int</span> i<span class="token punctuation">,</span> j<span class="token punctuation">,</span> k<span class="token punctuation">;</span>
    i <span class="token operator">=</span> blockIdx<span class="token punctuation">.</span>y <span class="token operator">*</span> blockDim<span class="token punctuation">.</span>y <span class="token operator">+</span> threadIdx<span class="token punctuation">.</span>y<span class="token punctuation">;</span>
    j <span class="token operator">=</span> blockIdx<span class="token punctuation">.</span>x <span class="token operator">*</span> blockDim<span class="token punctuation">.</span>x <span class="token operator">+</span> threadIdx<span class="token punctuation">.</span>x<span class="token punctuation">;</span>
    <span class="token comment">// 自身の番号から担当 (i,j) を決める</span>
    <span class="token keyword keyword-if">if</span> <span class="token punctuation">(</span>i <span class="token operator">&gt;=</span> n <span class="token operator">||</span> j <span class="token operator">&gt;=</span> n<span class="token punctuation">)</span> <span class="token keyword keyword-return">return</span><span class="token punctuation">;</span> <span class="token comment">// 行列からはみ出す部分は計算しない</span>
    <span class="token keyword keyword-for">for</span> <span class="token punctuation">(</span>k <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> k <span class="token operator">&lt;</span> n<span class="token punctuation">;</span> k<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span> <span class="token comment">// 総和の計算</span>
        C<span class="token punctuation">[</span>i<span class="token operator">*</span>n<span class="token operator">+</span>j<span class="token punctuation">]</span> <span class="token operator">+=</span> A<span class="token punctuation">[</span>i<span class="token operator">*</span>n<span class="token operator">+</span>k<span class="token punctuation">]</span> <span class="token operator">*</span> B<span class="token punctuation">[</span>k<span class="token operator">*</span>n<span class="token operator">+</span>j<span class="token punctuation">]</span><span class="token punctuation">;</span> <span class="token comment">// C[i][j] += A[i][k] * B[k][j]</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>

<span class="token keyword keyword-int">int</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token keyword keyword-int">int</span> argc<span class="token punctuation">,</span> <span class="token keyword keyword-char">char</span> <span class="token operator">*</span>argv<span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token punctuation">{</span>
    <span class="token keyword keyword-int">int</span> i<span class="token punctuation">,</span> j<span class="token punctuation">,</span> n<span class="token punctuation">;</span>
    <span class="token keyword keyword-double">double</span> <span class="token operator">*</span>A<span class="token punctuation">,</span> <span class="token operator">*</span>B<span class="token punctuation">,</span> <span class="token operator">*</span>C<span class="token punctuation">;</span>
    <span class="token keyword keyword-double">double</span> <span class="token operator">*</span>DA<span class="token punctuation">,</span> <span class="token operator">*</span>DA<span class="token punctuation">,</span> <span class="token operator">*</span>DC<span class="token punctuation">;</span>
    n <span class="token operator">=</span> <span class="token function">atoi</span><span class="token punctuation">(</span>argv<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// 行列の大きさ</span>
    <span class="token comment">// A, B, Cのためにホストメモリを確保</span>
    A <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token keyword keyword-double">double</span> <span class="token operator">*</span><span class="token punctuation">)</span><span class="token function">malloc</span><span class="token punctuation">(</span><span class="token keyword keyword-sizeof">sizeof</span><span class="token punctuation">(</span><span class="token keyword keyword-double">double</span><span class="token punctuation">)</span><span class="token operator">*</span>n<span class="token operator">*</span>n<span class="token punctuation">)</span><span class="token punctuation">;</span>
    B <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token keyword keyword-double">double</span> <span class="token operator">*</span><span class="token punctuation">)</span><span class="token function">malloc</span><span class="token punctuation">(</span><span class="token keyword keyword-sizeof">sizeof</span><span class="token punctuation">(</span><span class="token keyword keyword-double">double</span><span class="token punctuation">)</span><span class="token operator">*</span>n<span class="token operator">*</span>n<span class="token punctuation">)</span><span class="token punctuation">;</span>
    C <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token keyword keyword-double">double</span> <span class="token operator">*</span><span class="token punctuation">)</span><span class="token function">malloc</span><span class="token punctuation">(</span><span class="token keyword keyword-sizeof">sizeof</span><span class="token punctuation">(</span><span class="token keyword keyword-double">double</span><span class="token punctuation">)</span><span class="token operator">*</span>n<span class="token operator">*</span>n<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token comment">// A, Bの内容を設定し、Cをゼロクリア(略)</span>
    <span class="token comment">// A, B, Cのためにデバイスメモリを確保</span>
    <span class="token function">cudaMalloc</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token keyword keyword-void">void</span><span class="token operator">*</span><span class="token operator">*</span><span class="token punctuation">)</span><span class="token operator">&amp;</span>DA<span class="token punctuation">,</span> <span class="token keyword keyword-sizeof">sizeof</span><span class="token punctuation">(</span><span class="token keyword keyword-double">double</span><span class="token punctuation">)</span><span class="token operator">*</span>n<span class="token operator">*</span>n<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token function">cudaMalloc</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token keyword keyword-void">void</span><span class="token operator">*</span><span class="token operator">*</span><span class="token punctuation">)</span><span class="token operator">&amp;</span>DB<span class="token punctuation">,</span> <span class="token keyword keyword-sizeof">sizeof</span><span class="token punctuation">(</span><span class="token keyword keyword-double">double</span><span class="token punctuation">)</span><span class="token operator">*</span>n<span class="token operator">*</span>n<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token function">cudaMalloc</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token keyword keyword-void">void</span><span class="token operator">*</span><span class="token operator">*</span><span class="token punctuation">)</span><span class="token operator">&amp;</span>DC<span class="token punctuation">,</span> <span class="token keyword keyword-sizeof">sizeof</span><span class="token punctuation">(</span><span class="token keyword keyword-double">double</span><span class="token punctuation">)</span><span class="token operator">*</span>n<span class="token operator">*</span>n<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token comment">// A, B, Cの内容を、ホストメモリからデバイスメモリへコピー</span>
    <span class="token function">cudaMemcpy</span><span class="token punctuation">(</span>DA<span class="token punctuation">,</span> A<span class="token punctuation">,</span> <span class="token keyword keyword-sizeof">sizeof</span><span class="token punctuation">(</span><span class="token keyword keyword-double">double</span><span class="token punctuation">)</span><span class="token operator">*</span>n<span class="token operator">*</span>n<span class="token punctuation">,</span> cudaMemcpyHostToDevice<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token function">cudaMemcpy</span><span class="token punctuation">(</span>DB<span class="token punctuation">,</span> B<span class="token punctuation">,</span> <span class="token keyword keyword-sizeof">sizeof</span><span class="token punctuation">(</span><span class="token keyword keyword-double">double</span><span class="token punctuation">)</span><span class="token operator">*</span>n<span class="token operator">*</span>n<span class="token punctuation">,</span> cudaMemcpyHostToDevice<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token function">cudaMemcpy</span><span class="token punctuation">(</span>DC<span class="token punctuation">,</span> C<span class="token punctuation">,</span> <span class="token keyword keyword-sizeof">sizeof</span><span class="token punctuation">(</span><span class="token keyword keyword-double">double</span><span class="token punctuation">)</span><span class="token operator">*</span>n<span class="token operator">*</span>n<span class="token punctuation">,</span> cudaMemcpyHostToDevice<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token comment">// GPUカーネル関数を呼び出す!! 約n*n個のスレッドを使う</span>
    mm_gpu<span class="token operator">&lt;&lt;</span><span class="token operator">&lt;</span><span class="token function">dim3</span><span class="token punctuation">(</span><span class="token punctuation">(</span>n<span class="token operator">+</span>BS‐<span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">/</span>BS<span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>n<span class="token operator">+</span>BS‐<span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">/</span>BS<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token function">dim3</span><span class="token punctuation">(</span>BS<span class="token punctuation">,</span> BS<span class="token punctuation">)</span><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span>
        <span class="token punctuation">(</span>DA<span class="token punctuation">,</span> DB<span class="token punctuation">,</span> DC<span class="token punctuation">,</span> n<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token comment">// 結果のCを、デバイスメモリからホストメモリへコピー</span>
    <span class="token function">cudaMemcpy</span><span class="token punctuation">(</span>C<span class="token punctuation">,</span> DC<span class="token punctuation">,</span> <span class="token keyword keyword-sizeof">sizeof</span><span class="token punctuation">(</span><span class="token keyword keyword-double">double</span><span class="token punctuation">)</span><span class="token operator">*</span>n<span class="token operator">*</span>n<span class="token punctuation">,</span> cudaMemcpyDeviceToHost<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token comment">// Cを出力などに利用(略)</span>
    <span class="token keyword keyword-return">return</span> <span class="token number">0</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</pre></details>
<p>CUDAのプログラムは，xx.cuという拡張子で，Cベースで書かれます．これらは，概要としては</p>
<ul>
<li>CPUがGPUのメモリ上にデータ用領域を確保</li>
<li>CPUがGPUに入力されたデータを転送</li>
<li>CPUがGPUカーネル関数を呼び出し</li>
<li><strong>GPUが計算</strong></li>
<li>CPUがGPUの計算結果をCPUに送信</li>
</ul>
<p>の段階に分かれているようです．このうち，GPUが計算する部分が一番最初の記述，</p>
<pre data-role="codeBlock" data-info="C" class="language-c">__global__ <span class="token keyword keyword-void">void</span> <span class="token function">mm_gpu</span><span class="token punctuation">(</span><span class="token keyword keyword-double">double</span> <span class="token operator">*</span>A<span class="token punctuation">,</span> <span class="token keyword keyword-double">double</span> <span class="token operator">*</span>B<span class="token punctuation">,</span> <span class="token keyword keyword-double">double</span> <span class="token operator">*</span>C<span class="token punctuation">,</span> <span class="token keyword keyword-int">int</span> n<span class="token punctuation">)</span>
<span class="token punctuation">{</span>
    <span class="token keyword keyword-int">int</span> i<span class="token punctuation">,</span> j<span class="token punctuation">,</span> k<span class="token punctuation">;</span>
    i <span class="token operator">=</span> blockIdx<span class="token punctuation">.</span>y <span class="token operator">*</span> blockDim<span class="token punctuation">.</span>y <span class="token operator">+</span> threadIdx<span class="token punctuation">.</span>y<span class="token punctuation">;</span>
    j <span class="token operator">=</span> blockIdx<span class="token punctuation">.</span>x <span class="token operator">*</span> blockDim<span class="token punctuation">.</span>x <span class="token operator">+</span> threadIdx<span class="token punctuation">.</span>x<span class="token punctuation">;</span>
    <span class="token comment">// 自分の背番号から担当する (i,j) を決める</span>
    <span class="token keyword keyword-if">if</span> <span class="token punctuation">(</span>i <span class="token operator">&gt;=</span> n <span class="token operator">||</span> j <span class="token operator">&gt;=</span> n<span class="token punctuation">)</span> <span class="token keyword keyword-return">return</span><span class="token punctuation">;</span> <span class="token comment">// 行列からはみ出す部分は計算しない</span>
    <span class="token keyword keyword-for">for</span> <span class="token punctuation">(</span>k <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> k <span class="token operator">&lt;</span> n<span class="token punctuation">;</span> k<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span> <span class="token comment">// 総和を計算する部分</span>
        C<span class="token punctuation">[</span>i<span class="token operator">*</span>n<span class="token operator">+</span>j<span class="token punctuation">]</span> <span class="token operator">+=</span> A<span class="token punctuation">[</span>i<span class="token operator">*</span>n<span class="token operator">+</span>k<span class="token punctuation">]</span> <span class="token operator">*</span> B<span class="token punctuation">[</span>k<span class="token operator">*</span>n<span class="token operator">+</span>j<span class="token punctuation">]</span><span class="token punctuation">;</span> <span class="token comment">// C[i][j] += A[i][k] * B[k][j]に相当</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</pre><p>に値します．この部分をGPUカーネル関数と言い，それ以外の部分をホスト関数と言います．ホスト関数はCPU側で動くものですね．ということで，この関数，というかプログラムに対して引数として何をいれて(CPU-&gt;GPU)，何を出力させるか(GPU-&gt;CPU)をよく考えることと，そのためにどんな計算領域が必要になるか，あるいは用意させるか，そして最後に，どの変数はGPUからCPUに送信するのかなどを色々と工夫することが可能になりそうです．</p>
<p>一般に，CPUとGPUで情報のやり取りが生じると時間がかかってしまうらしいので，たとえばAとBを引数にしてCを算出するプログラムを考えた場合，GPUからはＣだけ送られれば十分なのでAとBは送らないといったことをすると高速化できるそうです．</p>
<p>このあたりは</p>
<pre data-role="codeBlock" data-info="C" class="language-c"><span class="token function">cudaMemcpy</span><span class="token punctuation">(</span>DA<span class="token punctuation">,</span> A<span class="token punctuation">,</span> <span class="token keyword keyword-sizeof">sizeof</span><span class="token punctuation">(</span><span class="token keyword keyword-double">double</span><span class="token punctuation">)</span><span class="token operator">*</span>n<span class="token operator">*</span>n<span class="token punctuation">,</span> cudaMemcpyHostToDevice<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token function">cudaMemcpy</span><span class="token punctuation">(</span>DB<span class="token punctuation">,</span> B<span class="token punctuation">,</span> <span class="token keyword keyword-sizeof">sizeof</span><span class="token punctuation">(</span><span class="token keyword keyword-double">double</span><span class="token punctuation">)</span><span class="token operator">*</span>n<span class="token operator">*</span>n<span class="token punctuation">,</span> cudaMemcpyHostToDevice<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token function">cudaMemcpy</span><span class="token punctuation">(</span>DC<span class="token punctuation">,</span> C<span class="token punctuation">,</span> <span class="token keyword keyword-sizeof">sizeof</span><span class="token punctuation">(</span><span class="token keyword keyword-double">double</span><span class="token punctuation">)</span><span class="token operator">*</span>n<span class="token operator">*</span>n<span class="token punctuation">,</span> cudaMemcpyHostToDevice<span class="token punctuation">)</span><span class="token punctuation">;</span>
</pre><p>の記述が関係するらしいです．引数は順に，転送先，転送元，サイズ(?)，Host(CPU)からDevice(GPU)なのか，あるいはその逆か，の4つになります．この例では，CPUからGPUに3つの変数を送っています．ここら辺については，また必要になったら掘り下げていきます．</p>
<p>次に，GPUにどれだけのスレッドを使わせるかを指定する記述です．</p>
<pre data-role="codeBlock" data-info="C" class="language-c"><span class="token comment">// GPUカーネル関数を呼び出す!! 約n*n個のスレッドを使う</span>
    mm_gpu<span class="token operator">&lt;&lt;</span><span class="token operator">&lt;</span><span class="token function">dim3</span><span class="token punctuation">(</span><span class="token punctuation">(</span>n<span class="token operator">+</span>BS‐<span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">/</span>BS<span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>n<span class="token operator">+</span>BS‐<span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">/</span>BS<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token function">dim3</span><span class="token punctuation">(</span>BS<span class="token punctuation">,</span> BS<span class="token punctuation">)</span><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span>
        <span class="token punctuation">(</span>DA<span class="token punctuation">,</span> DB<span class="token punctuation">,</span> DC<span class="token punctuation">,</span> n<span class="token punctuation">)</span><span class="token punctuation">;</span>
</pre><p>mm_gpuは関数の名前で，&lt;&lt;&lt;&gt;&gt;&gt;が使用するスレッドの数の指定になるようです．これもよく分からない．(DA,DB,DC,n)は関数に渡したい引数のようですね．いずれにせよ，ここの記述によって，どれだけスレッドを使用するのか，(=どれだけGPUに頑張らせるのか？)を指定できるようです．</p>
<p>ともかく，これで呼び出された関数が</p>
<pre data-role="codeBlock" data-info="C" class="language-c">__global__ <span class="token keyword keyword-void">void</span> <span class="token function">mm_gpu</span><span class="token punctuation">(</span><span class="token keyword keyword-double">double</span> <span class="token operator">*</span>A<span class="token punctuation">,</span> <span class="token keyword keyword-double">double</span> <span class="token operator">*</span>B<span class="token punctuation">,</span> <span class="token keyword keyword-double">double</span> <span class="token operator">*</span>C<span class="token punctuation">,</span> <span class="token keyword keyword-int">int</span> n<span class="token punctuation">)</span>
<span class="token punctuation">{</span>
    <span class="token keyword keyword-int">int</span> i<span class="token punctuation">,</span> j<span class="token punctuation">,</span> k<span class="token punctuation">;</span>
    i <span class="token operator">=</span> blockIdx<span class="token punctuation">.</span>y <span class="token operator">*</span> blockDim<span class="token punctuation">.</span>y <span class="token operator">+</span> threadIdx<span class="token punctuation">.</span>y<span class="token punctuation">;</span>
    j <span class="token operator">=</span> blockIdx<span class="token punctuation">.</span>x <span class="token operator">*</span> blockDim<span class="token punctuation">.</span>x <span class="token operator">+</span> threadIdx<span class="token punctuation">.</span>x<span class="token punctuation">;</span>
    <span class="token comment">// 自身の担当する (i,j) を決める</span>
    <span class="token keyword keyword-if">if</span> <span class="token punctuation">(</span>i <span class="token operator">&gt;=</span> n <span class="token operator">||</span> j <span class="token operator">&gt;=</span> n<span class="token punctuation">)</span> <span class="token keyword keyword-return">return</span><span class="token punctuation">;</span> <span class="token comment">// 行列からはみ出す部分は計算しない</span>
    <span class="token keyword keyword-for">for</span> <span class="token punctuation">(</span>k <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> k <span class="token operator">&lt;</span> n<span class="token punctuation">;</span> k<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span> <span class="token comment">// 総和</span>
        C<span class="token punctuation">[</span>i<span class="token operator">*</span>n<span class="token operator">+</span>j<span class="token punctuation">]</span> <span class="token operator">+=</span> A<span class="token punctuation">[</span>i<span class="token operator">*</span>n<span class="token operator">+</span>k<span class="token punctuation">]</span> <span class="token operator">*</span> B<span class="token punctuation">[</span>k<span class="token operator">*</span>n<span class="token operator">+</span>j<span class="token punctuation">]</span><span class="token punctuation">;</span> <span class="token comment">// C[i][j] += A[i][k] * B[k][j]に相当</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</pre><p>ということになりそうです．解読します．</p>
<p>まず，最初の__global__はGPUカーネル関数の印です．そしてvoid以降が関数の定義で，関数名および引数の指定をしています．</p>
<p>次にintであるiとjを使って，自身の担当する要素を指定しています．blockやらthreadやらが出てきてよく分かりませんが，とりあえずこれがそれぞれの割り当てになります．</p>
<p>それぞれのスレッド？の担当が決まったら，あとはそれに合わせて計算を割り振るだけです．</p>
<p>それぞれの計算機に課される仕事は，自身の担当する<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>C</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow><annotation encoding="application/x-tex">C_{ij}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">ij</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span>を計算することです．このサンプルコードだとABCの形はn*nの長さをもった1次元配列の形を取っているので，たとえば<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>C</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow><annotation encoding="application/x-tex">C_{ij}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">ij</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span>は<code>C[i*n+j]</code>でアクセスできます．</p>
<p>ということで</p>
<pre data-role="codeBlock" data-info="C" class="language-c"><span class="token keyword keyword-for">for</span> <span class="token punctuation">(</span>k <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> k <span class="token operator">&lt;</span> n<span class="token punctuation">;</span> k<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span> <span class="token comment">// 総和</span>
        C<span class="token punctuation">[</span>i<span class="token operator">*</span>n<span class="token operator">+</span>j<span class="token punctuation">]</span> <span class="token operator">+=</span> A<span class="token punctuation">[</span>i<span class="token operator">*</span>n<span class="token operator">+</span>k<span class="token punctuation">]</span> <span class="token operator">*</span> B<span class="token punctuation">[</span>k<span class="token operator">*</span>n<span class="token operator">+</span>j<span class="token punctuation">]</span><span class="token punctuation">;</span> <span class="token comment">// C[i][j] += A[i][k] * B[k][j]に相当</span>
    <span class="token punctuation">}</span>
</pre><p>つまり<br>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>C</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>=</mo><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>0</mn></mrow><mrow><mi>n</mi><mo>−</mo><mn>1</mn></mrow></munderover><msub><mi>A</mi><mrow><mi>i</mi><mi>k</mi></mrow></msub><mo>×</mo><msub><mi>B</mi><mrow><mi>k</mi><mi>j</mi></mrow></msub></mrow><annotation encoding="application/x-tex">C_{ij} = \sum_{k=0}^{n-1} A_{ik} \times B_{kj}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">ij</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:3.1032em;vertical-align:-1.3021em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8011em;"><span style="top:-1.8479em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="mrel mtight">=</span><span class="mord mtight">0</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.3021em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">ik</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0502em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">kj</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span></span></p>
<p>をするだけとなります．</p>
<p>CPUの場合は，一つの計算機というか単位が計算を担当するため，順番に処理しないといけなくなり，実装としては</p>
<pre data-role="codeBlock" data-info="C" class="language-c"><span class="token keyword keyword-for">for</span> <span class="token punctuation">(</span>i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> n<span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span> <span class="token comment">// i行目，</span>
    <span class="token keyword keyword-for">for</span> <span class="token punctuation">(</span>j <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> j <span class="token operator">&lt;</span> n<span class="token punctuation">;</span> j<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span> <span class="token comment">// 第j列に注目</span>
        <span class="token keyword keyword-for">for</span> <span class="token punctuation">(</span>k <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> k <span class="token operator">&lt;</span> n<span class="token punctuation">;</span> k<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span> <span class="token comment">// 次元数分，下の計算をやる</span>
            c<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span> <span class="token operator">+=</span> a<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>k<span class="token punctuation">]</span><span class="token operator">*</span>b<span class="token punctuation">[</span>k<span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">;</span> <span class="token comment">// cijはaikとbkjの積</span>
        <span class="token punctuation">}</span> <span class="token punctuation">}</span> <span class="token punctuation">}</span>
</pre><p>のように3重のループ構造になっていました．このうち，2つのループをなくして別々のユニットに計算させるのがCUDAプログラムのメリットでした．</p>
<h2 class="mume-header" id="cupy">CuPy</h2>

<p>以上のように，CUDAを使ったGPUプログラミングの基本がなんとなく読めてきたところで，本題のCuPyの使い方を確認します．</p>
<h3 class="mume-header" id="cupy%E3%81%A8%E3%81%AF">CuPyとは</h3>

<p>CuPyはPreferred Networks社が開発しているオープンソースの高速な行列計算ライブラリです．中身としては，NumPyのGPU版のようなもので，基本的にはNumPyベースで動くプログラムであればnpをcpに変えるだけで動いてくれます．</p>
<p>DeepLearningのフレームワークであるChainerのバックグラウンドでも動いているようです．</p>
<img src="../figures/cupy.png">
<h3 class="mume-header" id="cupy%E3%81%AB%E3%82%88%E3%82%8Bnumpy%E3%81%AE%E4%BA%92%E6%8F%9B%E3%83%97%E3%83%AD%E3%82%B0%E3%83%A9%E3%83%A0">CuPyによるNumPyの互換プログラム</h3>

<p>まずは軽く使い方を確認していきます．GitではCuPy.ipynbです．</p>
<p>まずは必要なライブラリのimport</p>
<details><summary>code</summary>
<pre data-role="codeBlock" data-info="Python{.line-numbers}" class="language-python line-numbers"><span class="token keyword keyword-import">import</span> numpy <span class="token keyword keyword-as">as</span> np
<span class="token keyword keyword-import">import</span> cupy <span class="token keyword keyword-as">as</span> cp

<span class="token keyword keyword-from">from</span> skimage <span class="token keyword keyword-import">import</span> data<span class="token punctuation">,</span>transform<span class="token punctuation">,</span>color<span class="token punctuation">,</span>io
<span class="token keyword keyword-import">import</span> time
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></pre></details>
<p>次に，性能評価をするためにフーリエ変換にかける画像を読み込みます．</p>
<pre data-role="codeBlock" data-info="Python{.line-numbers}" class="language-python line-numbers">np_img <span class="token operator">=</span> data<span class="token punctuation">.</span>astronaut<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment">#画像ロード</span>

np_img <span class="token operator">=</span> color<span class="token punctuation">.</span>rgb2gray<span class="token punctuation">(</span>np_img<span class="token punctuation">)</span><span class="token comment">#グレースケール化</span>
np_img <span class="token operator">=</span> np_img<span class="token punctuation">.</span>astype<span class="token punctuation">(</span><span class="token string">'f'</span><span class="token punctuation">)</span>

io<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>np_img<span class="token punctuation">)</span><span class="token comment">#画像の表示</span>

cp_img <span class="token operator">=</span> cp<span class="token punctuation">.</span>asarray<span class="token punctuation">(</span>np_img<span class="token punctuation">)</span><span class="token comment">#numpy配列をcupy配列に変換</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre><p>ここで，numpyで定義した配列をcupy配列に変換するためには<code>cp.asarray</code>関数を使用します．おそらくですが，これをあまりやりすぎると計算が遅くなると思うので極力forには含みません．</p>
<p>では早速，計算性能の比較をしていきます．まずはNumPy，つまりCPUで計算させる普通のプログラムです．</p>
<pre data-role="codeBlock" data-info="Python{.line-numbers}" class="language-python line-numbers">times_cpu <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>  <span class="token comment"># CPUの計算時間保存用</span>

<span class="token keyword keyword-for">for</span> N <span class="token keyword keyword-in">in</span> <span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">100</span><span class="token punctuation">,</span><span class="token number">1000</span><span class="token punctuation">,</span><span class="token number">10000</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
    time_start <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>
    
    <span class="token keyword keyword-for">for</span> i <span class="token keyword keyword-in">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>N<span class="token punctuation">)</span><span class="token punctuation">:</span>
        sainokawara <span class="token operator">=</span> np<span class="token punctuation">.</span>fft<span class="token punctuation">.</span>fft<span class="token punctuation">(</span>np<span class="token punctuation">.</span>fft<span class="token punctuation">.</span>ifft<span class="token punctuation">(</span>np<span class="token punctuation">.</span>fft<span class="token punctuation">.</span>fft<span class="token punctuation">(</span>np_img<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        
    time_end <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>
    elapsed_time <span class="token operator">=</span> time_end <span class="token operator">-</span> time_start  <span class="token comment"># 経過時間</span>
    
    times_cpu<span class="token punctuation">.</span>append<span class="token punctuation">(</span>elapsed_time<span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre><p>同様にCuPyも．</p>
<details><summary>code</summary>
<pre data-role="codeBlock" data-info="Python{.line-numbers}" class="language-python line-numbers">times_gpu <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>  <span class="token comment"># GPUの計算時間保存用</span>

<span class="token keyword keyword-for">for</span> N <span class="token keyword keyword-in">in</span> <span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">100</span><span class="token punctuation">,</span><span class="token number">1000</span><span class="token punctuation">,</span><span class="token number">10000</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
    time_start <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>
    
    <span class="token keyword keyword-for">for</span> i <span class="token keyword keyword-in">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>N<span class="token punctuation">)</span><span class="token punctuation">:</span>
        sainokawara <span class="token operator">=</span> cp<span class="token punctuation">.</span>fft<span class="token punctuation">.</span>fft<span class="token punctuation">(</span>cp<span class="token punctuation">.</span>fft<span class="token punctuation">.</span>ifft<span class="token punctuation">(</span>cp<span class="token punctuation">.</span>fft<span class="token punctuation">.</span>fft<span class="token punctuation">(</span>cp_img<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        
    time_end <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>
    elapsed_time <span class="token operator">=</span> time_end <span class="token operator">-</span> time_start  <span class="token comment"># 経過時間</span>
    
    times_gpu<span class="token punctuation">.</span>append<span class="token punctuation">(</span>elapsed_time<span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></details>
<p>CuPyはNumPyのnpをcpに変換しただけです．これで計算が済んだので，結果を比較してみます．</p>
<details><summary>code</summary>
<pre data-role="codeBlock" data-info="Python{.line-numbers}" class="language-python line-numbers"><span class="token keyword keyword-import">import</span> tabulate

<span class="token comment"># N ごとの実行時間の差</span>
N <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">1000</span><span class="token punctuation">,</span> <span class="token number">10000</span><span class="token punctuation">]</span>
times_cpu <span class="token operator">=</span> np<span class="token punctuation">.</span>asarray<span class="token punctuation">(</span>times_cpu<span class="token punctuation">)</span>
times_gpu <span class="token operator">=</span> np<span class="token punctuation">.</span>asarray<span class="token punctuation">(</span>times_gpu<span class="token punctuation">)</span>

<span class="token comment"># tabulate を用いてテーブルを作成</span>
table <span class="token operator">=</span> tabulate<span class="token punctuation">.</span>tabulate<span class="token punctuation">(</span>
    <span class="token builtin">zip</span><span class="token punctuation">(</span>N<span class="token punctuation">,</span> times_cpu<span class="token punctuation">,</span> times_gpu<span class="token punctuation">)</span><span class="token punctuation">,</span>
    headers<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'N'</span><span class="token punctuation">,</span> <span class="token string">'NumPyでの実行時間 (sec)'</span><span class="token punctuation">,</span> <span class="token string">'CuPy での実行時間 (sec)'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token keyword keyword-print">print</span><span class="token punctuation">(</span>table<span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></details>
<center><img src="../figures/speed.png" ,="" width="70%"></center>
<p>圧倒的にCuPyの方が早いことが確認できました．NumPy自体が行列演算に特化したライブラリなので，それをさらにGPUで行うためにこのように早くなるわけですね．CUDAのプログラムを書かなくてもGPUが利用できるのはとても便利です．</p>
<p>ちなみに，この速さはあくまでcp(np)を使った演算をしているからですので，同じように行列の演算であってもnpを使わない実装をしていた部分に関してはむしろ遅くなってしまいます．</p>
<p>たとえば，forで回しまくっていたプログラムであれば，これをGPUに投げ渡してしまうと1つのユニット，それもCPUよりも貧弱な計算能力のものに全て計算を任せるわけですから，途方もない時間かかってしまいます．</p>
<p>従って，<strong>CuPyベースのプログラムでは，cp関数での計算以外は高速化できない</strong>ことになります．</p>
<p>たとえば，自分が書いていたコードですが</p>
<pre data-role="codeBlock" data-info="Python" class="language-python"><span class="token keyword keyword-for">for</span> post_neuron <span class="token keyword keyword-in">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    self<span class="token punctuation">.</span>W<span class="token punctuation">[</span>post_neuron<span class="token punctuation">]</span> <span class="token operator">+=</span> self<span class="token punctuation">.</span>learning_rate <span class="token operator">*</span> <span class="token punctuation">(</span>self<span class="token punctuation">.</span>x<span class="token punctuation">[</span>post_neuron<span class="token punctuation">]</span> <span class="token operator">*</span> self<span class="token punctuation">.</span>x         <span class="token operator">-</span> cp<span class="token punctuation">.</span>square<span class="token punctuation">(</span>self<span class="token punctuation">.</span>x<span class="token punctuation">[</span>post_neuron<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">*</span> self<span class="token punctuation">.</span>W<span class="token punctuation">[</span>post_neuron<span class="token punctuation">]</span><span class="token punctuation">)</span>
</pre><p>という記述が，逐次的に呼び出されていた場合，cupyを使うことでむしろ遅くなります．これが仮に</p>
<pre data-role="codeBlock" data-info="Python" class="language-python"><span class="token keyword keyword-for">for</span> post_neuron <span class="token keyword keyword-in">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    cp<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>a<span class="token punctuation">,</span>b<span class="token punctuation">)</span>
</pre><p>のような記述だったら早かったはずです．しかし，これではやや不便です．numpyの関数にない計算をさせたいことだってたくさんあります．</p>
<h2 class="mume-header" id="cupyelementwisekernel">CuPy.ElementwiseKernel</h2>

<p>npをcpに変えるのは，CPUに最適化された実装からGPUに最適化された実装への変換を意味します．</p>
<p>しかし，そもそもCPUへの最適化も難しく，あるいは開発者の頭が足りず，Pythonのforループで頑張って実装していた部分をGPUで早くしたい．というモチベーションもあり得ます．</p>
<p>そんな時につかうのがCuPyのElementwiseKernelという機能で，CUDAのGPUカーネルの中身を直接書いてCUDAを呼び出すことが出来ます．</p>
<p>メリットとして，上で見てきたようにブロックやスレッドの数，メモリ管理のようなよく分からなかった部分は触らず(勝手に調整してくれる)に，GPUにやってもらいたい計算部分(=GPUカーネル関数)のみを書けるということがあります．</p>
<p>やっていきます．</p>
<p>まずはシンプルに，二つの正方行列の和を計算させます．</p>
<pre data-role="codeBlock" data-info="Python{.line-numbers}" class="language-python line-numbers">X <span class="token operator">=</span> cp<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">25</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span>
Y <span class="token operator">=</span> cp<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">25</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span>

<span class="token comment"># ありものの関数で計算</span>
arimono <span class="token operator">=</span> cp<span class="token punctuation">.</span>add<span class="token punctuation">(</span>X<span class="token punctuation">,</span>Y<span class="token punctuation">)</span>

<span class="token comment"># カーネル関数を定義、生成</span>
mat_add_kernel <span class="token operator">=</span> cp<span class="token punctuation">.</span>ElementwiseKernel<span class="token punctuation">(</span>
        in_params<span class="token operator">=</span><span class="token string">'int32 x, int32 y'</span><span class="token punctuation">,</span> <span class="token comment"># input parameterを指定する．型の指定はしないとっぽい．Cだからかな</span>
        out_params<span class="token operator">=</span><span class="token string">'float32 z'</span><span class="token punctuation">,</span>       <span class="token comment"># output parameterの指定．</span>
        operation<span class="token operator">=</span>\                   <span class="token comment"># 実行する関数の中身を記述する．これでnpにないものも使える</span>
        <span class="token triple-quoted-string string">'''
        z = x + y;
        '''</span><span class="token punctuation">,</span>
        name<span class="token operator">=</span><span class="token string">'mat_add_kernel'</span><span class="token punctuation">)</span>        <span class="token comment"># 関数名</span>

<span class="token comment"># カーネル関数の呼び出し</span>
Z <span class="token operator">=</span> mat_add_kernel<span class="token punctuation">(</span>X<span class="token punctuation">,</span> Y<span class="token punctuation">)</span>

<span class="token keyword keyword-print">print</span><span class="token punctuation">(</span><span class="token string">'cp.add = \n'</span><span class="token punctuation">,</span> arimono<span class="token punctuation">)</span>
<span class="token keyword keyword-print">print</span><span class="token punctuation">(</span><span class="token string">'carnel = \n'</span><span class="token punctuation">,</span> Z<span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre><p>てきとうに，XとYの2つの正方行列を定義し，その和を計算させています．<br>
この程度であれば，numpyおよびcupyの.add関数で計算可能ですので，ひとまずさせておいて，自分で実装したものと計算結果を比較してみます．</p>
<p>実装の詳細はとりあえず省き，結果を出してみると</p>
<center><img src="../figures/result.png" ,="" width="30%"></center>
<p>と一致していることが分かります．型は違っていますが，わざとです．とりあえず，CuPy.ElementwiseKernelで普通のcp関数を再現できることが確認できました．</p>
<p>では実際の実装について見ていきます．</p>
<pre data-role="codeBlock" data-info="Python{.line-numbers}" class="language-python line-numbers"><span class="token comment"># カーネル関数を定義、生成</span>
mat_add_kernel <span class="token operator">=</span> cp<span class="token punctuation">.</span>ElementwiseKernel<span class="token punctuation">(</span>
        in_params<span class="token operator">=</span><span class="token string">'int32 x, int32 y'</span><span class="token punctuation">,</span> <span class="token comment"># input parameterを指定する．型の指定はしないとっぽい．Cだからかな</span>
        out_params<span class="token operator">=</span><span class="token string">'float32 z'</span><span class="token punctuation">,</span>       <span class="token comment"># output parameterの指定．</span>
        operation<span class="token operator">=</span>\                   <span class="token comment"># 実行する関数の中身を記述する．これでnpにないものも使える</span>
        <span class="token triple-quoted-string string">'''
        z = x + y;
        '''</span><span class="token punctuation">,</span>
        name<span class="token operator">=</span><span class="token string">'mat_add_kernel'</span><span class="token punctuation">)</span>        <span class="token comment"># 関数名</span>

<span class="token comment"># カーネル関数の呼び出し</span>
Z <span class="token operator">=</span> mat_add_kernel<span class="token punctuation">(</span>X<span class="token punctuation">,</span> Y<span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre><p>GPUに関連するのはこの部分だけです．11,12行目は，それ以前で定義した関数を呼び出しているだけなので，中身自体は9行です．CuPy.ElementwiseKernelでのカーネル関数の定義には4つの要素が必要になるようなので，順に確認していきます．</p>
<ul>
<li>in_params</li>
<li>out_params</li>
<li>operation</li>
<li>name</li>
</ul>
<p>まず，<code>in_params</code>は引数です．この関数を呼び出すさいに用いる変数ですね．12行目で関数を呼び出す際，XとYが引数として与えられています．関数の定義時には，この関数がどういった値を受け取って動作するのかを型とともに指定してやる必要があります．Cっぽいですね．ここでは，正方行列の定義は普通に整数値だったのでint32を型として，2つの引数がくると定義しました．</p>
<p>次に，<code>out_params</code>です．こちらはそのまま，出力されるパラメータの定義ですね．12行目で呼び出された後はZに格納される値の定義です．単純にint同士の和なのでintで良いですが，型の指定が大事ってことを強調するためにfloatにしてみました．実際結果を見てみても，kernel関数にやらせた方では出力の値がfloatになっていたと思います．</p>
<p>次，<code>operation</code>ですが，ここに具体的な計算の内容を記述することになります．今回は行列の和なので単純に足し算だけ書いています．</p>
<p>最後に<code>name</code>ですが，こちらは関数の名前です．といっても，1行目でも既に指定しているのでよく分かりません．必要なんですかねこれ．</p>
<h3 class="mume-header" id="%E9%85%8D%E5%88%97%E3%81%AEindexing">配列のindexing</h3>

<p>個人的に，GPUを使いたくなった理由は自作のニューラルネットワークにシナプス可塑性を導入した際，膨れ上がった計算時間を短縮することでした．シナプスの繋がりは，細胞数の二乗になるため，</p>
<pre data-role="codeBlock" data-info="Python{.line-numbers}" class="language-python line-numbers"><span class="token keyword keyword-for">for</span> t <span class="token keyword keyword-in">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>入力刺激の長さ<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># リザバー結合重み行列の更新</span>
    <span class="token keyword keyword-for">for</span> post_neuron <span class="token keyword keyword-in">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>ニューロン数<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword keyword-for">for</span> pre_neuron <span class="token keyword keyword-in">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>ニューロン数<span class="token punctuation">)</span><span class="token punctuation">:</span>
            W<span class="token punctuation">[</span>post_neuron<span class="token punctuation">,</span> pre_neuron<span class="token punctuation">]</span> <span class="token operator">+=</span> 増加分<span class="token punctuation">(</span>仮にX<span class="token punctuation">[</span>post<span class="token punctuation">]</span><span class="token operator">*</span>X<span class="token punctuation">[</span>pre<span class="token punctuation">]</span><span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></pre><details><summary>正確なコード</summary>
<pre data-role="codeBlock" data-info="Python{.line-numbers}" class="language-python line-numbers"><span class="token comment"># 変数</span>
T <span class="token operator">=</span> <span class="token number">500</span>        <span class="token comment"># 入力時系列の長さ</span>
N_x <span class="token operator">=</span> <span class="token number">200</span>      <span class="token comment"># 中間層の数</span>
N_in <span class="token operator">=</span> <span class="token number">1</span>       <span class="token comment"># 入力層の数</span>
N_out <span class="token operator">=</span> <span class="token number">1</span>      <span class="token comment"># 出力層の数</span>
activation_func <span class="token operator">=</span> np<span class="token punctuation">.</span>tanh   <span class="token comment"># 活性化関数</span>
learning_rate <span class="token operator">=</span> <span class="token number">0.000001</span>   <span class="token comment"># 可塑性の学習率</span>
np<span class="token punctuation">.</span>seed <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span>seed<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>

<span class="token comment"># 入力時系列データ</span>
U <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>T<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>

<span class="token comment"># 入力から中間層への結合重みの初期化</span>
Win <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>uniform<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token punctuation">(</span>N_x<span class="token punctuation">,</span> N_in<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># 中間層の状態ベクトルの初期化</span>
x <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>N_x<span class="token punctuation">)</span>
W <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>uniform<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token punctuation">(</span>N_x<span class="token punctuation">,</span> N_x<span class="token punctuation">)</span><span class="token punctuation">)</span>

train_len <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>U<span class="token punctuation">)</span>

<span class="token comment"># 時間発展</span>
<span class="token keyword keyword-for">for</span> n <span class="token keyword keyword-in">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>train_len<span class="token punctuation">)</span><span class="token punctuation">:</span>
    x_in <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>Win<span class="token punctuation">,</span> U<span class="token punctuation">[</span>n<span class="token punctuation">]</span><span class="token punctuation">)</span>
    x <span class="token operator">=</span> x <span class="token operator">+</span> activation_func<span class="token punctuation">(</span>np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>W<span class="token punctuation">,</span> x<span class="token punctuation">)</span> <span class="token operator">+</span> x_in<span class="token punctuation">)</span>
        
    <span class="token comment"># リザバー結合重み行列の更新</span>
    <span class="token keyword keyword-for">for</span> post_neuron <span class="token keyword keyword-in">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>N_x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        W<span class="token punctuation">[</span>post_neuron<span class="token punctuation">]</span> <span class="token operator">+=</span> learning_rate <span class="token operator">*</span> <span class="token punctuation">(</span>x<span class="token punctuation">[</span>post_neuron<span class="token punctuation">]</span> <span class="token operator">*</span> x         <span class="token operator">-</span> np<span class="token punctuation">.</span>square<span class="token punctuation">(</span>x<span class="token punctuation">[</span>post_neuron<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">*</span> W<span class="token punctuation">[</span>post_neuron<span class="token punctuation">]</span><span class="token punctuation">)</span>
        
    <span class="token comment"># リザバー結合重み行列の更新(for 書き下し)</span>
    <span class="token comment">#for post_neuron in range(N_x):</span>
    <span class="token comment">#    for pre_neuron in range(N_x):</span>
    <span class="token comment">#        W2[post_neuron, pre_neuron] += learning_rate * (x[post_neuron] * x[pre_neuron]         - np.square(x[post_neuron]) * W2[post_neuron, pre_neuron])</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></details>
<p>のような実装が必要になります．このような多重for文はcupyにそのまま渡してしまうと計算が重くなりすぎるので，elementwisekernelを使って上手く計算させる必要があります(多分).</p>
<pre data-role="codeBlock" data-info="Python{.line-numbers}" class="language-python line-numbers">hebbian <span class="token operator">=</span> cp<span class="token punctuation">.</span>ElementwiseKernel<span class="token punctuation">(</span>
        in_params<span class="token operator">=</span><span class="token string">'float64 W, float64 X'</span><span class="token punctuation">,</span>
        out_params<span class="token operator">=</span><span class="token string">'W'</span><span class="token punctuation">,</span>
        operation<span class="token operator">=</span>\
        <span class="token triple-quoted-string string">'''
        W[post][pre] += x[post] * x[pre];
        
        '''</span><span class="token punctuation">,</span>
        name<span class="token operator">=</span><span class="token string">'hebbian'</span><span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre><p>のような実装を目指します．</p>
<p>ここでXはニューロンの状態ベクトル，Wはその組み合わせ間のシナプス結合重み行列です．たとえば<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>W</mi><mn>32</mn></msub></mrow><annotation encoding="application/x-tex">W_{32}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">32</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>は2個目のニューロンから3個目のニューロンへの結合重みです．この重みをhebb則に従って調整するためには，シナプス前細胞と後細胞の活動を，配列Wのインデックスに従って参照する必要があります．</p>
<p>cp.ElementwiseKernelでは，添え字アクセスを使うには，引数の指定の際に <strong>raw</strong>をつけます．これによって，指定した引数に対し特殊変数iを使うことが出来るようになります．</p>
<p>また，インデックス処理の際には出力する配列の大きさは先に決めておく必要があるようです．それに関係し，関数の呼び出しの際にも引数として出力変数を指定します．</p>
<p>挙動を確認してみます．</p>
<pre data-role="codeBlock" data-info="Python{.line-numbers}" class="language-python line-numbers">X <span class="token operator">=</span> cp<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">25</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span>cp<span class="token punctuation">.</span>int16<span class="token punctuation">)</span>
Y <span class="token operator">=</span> cp<span class="token punctuation">.</span>zeros_like<span class="token punctuation">(</span>X<span class="token punctuation">)</span> <span class="token comment"># yにあらかじめ出力の入れ物を用意</span>
Z <span class="token operator">=</span> cp<span class="token punctuation">.</span>zeros_like<span class="token punctuation">(</span>X<span class="token punctuation">)</span> <span class="token comment"># yにあらかじめ出力の入れ物を用意</span>

kernel <span class="token operator">=</span> cp<span class="token punctuation">.</span>ElementwiseKernel<span class="token punctuation">(</span>
    in_params <span class="token operator">=</span> <span class="token string">'raw int16 X, int16 shift, int16 width'</span><span class="token punctuation">,</span>  <span class="token comment"># x に raw を指定</span>
    out_params <span class="token operator">=</span> <span class="token string">'int16 Y, int16 Z'</span><span class="token punctuation">,</span>
    operation<span class="token operator">=</span>\
    <span class="token triple-quoted-string string">'''
    Y = X[i]+shift;
    Z = i;
    '''</span><span class="token punctuation">,</span>
    name<span class="token operator">=</span><span class="token string">'kernel'</span><span class="token punctuation">)</span>

kernel<span class="token punctuation">(</span>X<span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span>X<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>Y<span class="token punctuation">,</span>Z<span class="token punctuation">)</span> <span class="token comment"># 引数に出力も追加しなければならない</span>

<span class="token keyword keyword-print">print</span><span class="token punctuation">(</span><span class="token string">'Y = \n'</span><span class="token punctuation">,</span> Y<span class="token punctuation">)</span>
<span class="token keyword keyword-print">print</span><span class="token punctuation">(</span><span class="token string">'Z = \n'</span><span class="token punctuation">,</span> Z<span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre><center><img src="../figures/result2.png" ,="" width="30%"></center>
<p>上のコードでは，5*5に並んだ0の配列Xが与えられ，indexを取得しています．これを利用し，Xの各要素(といっても0ですが)に2を足したものをＹとしました．ここまでは普通です．</p>
<p>次にZですが，こちらはXから取得したindexそのものの配列です．中身を確認してみると，0から24の数字が振られています．<strong>rawによるindexingは行を無視した通し番号</strong>になるということですね．</p>
<p>これにより，多次元配列での実装で(x,y)にアクセスしたいなどといった際には多少工夫が必要です．</p>
<h2 class="mume-header" id="ojas-hebbian-rule%E3%81%AE%E5%AE%9F%E8%A3%85">Oja's hebbian ruleの実装</h2>

<p>以上の勉強内容を踏まえて，冒頭のシナプス可塑性を実装してみたのが以下の記述です．</p>
<pre data-role="codeBlock" data-info="C{.line-numbers}" class="language-c line-numbers">kernel <span class="token operator">=</span> cp<span class="token punctuation">.</span><span class="token function">ElementwiseKernel</span><span class="token punctuation">(</span>
    in_params <span class="token operator">=</span> 'raw float64 W<span class="token punctuation">,</span> raw float64 x<span class="token punctuation">,</span> int16 width<span class="token punctuation">,</span> float64 learning_rate'<span class="token punctuation">,</span>
    out_params <span class="token operator">=</span> <span class="token char">'raw float64 W_new'</span><span class="token punctuation">,</span>
    operation<span class="token operator">=</span>\
    <span class="token char">''</span>'
    <span class="token keyword keyword-int">int</span> x_idx <span class="token operator">=</span> i<span class="token operator">%</span>width<span class="token punctuation">;</span> <span class="token comment">// pre synapse</span>
    <span class="token keyword keyword-int">int</span> y_idx <span class="token operator">=</span> i<span class="token operator">/</span>width<span class="token punctuation">;</span> <span class="token comment">// post synapse</span>
    
    W_new<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> learning_rate <span class="token operator">*</span> <span class="token punctuation">(</span>x<span class="token punctuation">[</span>y_idx<span class="token punctuation">]</span><span class="token operator">*</span>x<span class="token punctuation">[</span>x_idx<span class="token punctuation">]</span> <span class="token operator">-</span> x<span class="token punctuation">[</span>y_idx<span class="token punctuation">]</span><span class="token operator">*</span>x<span class="token punctuation">[</span>y_idx<span class="token punctuation">]</span><span class="token operator">*</span>W<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token char">''</span>'<span class="token punctuation">,</span>
    name<span class="token operator">=</span><span class="token char">'kernel'</span><span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre><p>入力として，</p>
<ul>
<li>可塑性が効く前の結合重み行列 W</li>
<li>ニューロン状態ベクトル x</li>
<li>ニューロンの個数 width</li>
<li>学習率 learning_rate</li>
</ul>
<p>を読み込み，出力として</p>
<ul>
<li>可塑性が効いた後の結合重み行列 W_new</li>
</ul>
<p>を排出しています．このうち，結合重み行列からindexを取得し，行と列からそれぞれシナプス前後のニューロンの指定を行うために<code>x_idx</code> <code>y_idx</code>を定義しました．これらを用いて，OjaのHebbian ruleに従って差分を計算する関数です．mainのプログラムは</p>
<details><summary>code</summary>
<pre data-role="codeBlock" data-info="Python{.line-numbers}" class="language-python line-numbers">kernel <span class="token operator">=</span> cp<span class="token punctuation">.</span>ElementwiseKernel<span class="token punctuation">(</span>
    in_params <span class="token operator">=</span> <span class="token string">'raw float64 W, raw float64 x, int16 width, float64 learning_rate'</span><span class="token punctuation">,</span>
    out_params <span class="token operator">=</span> <span class="token string">'raw float64 W_new'</span><span class="token punctuation">,</span>
    operation<span class="token operator">=</span>\
    <span class="token triple-quoted-string string">'''
    int x_idx = i%width; 
    int y_idx = i/width;
    
    W_new[i] = learning_rate * (x[y_idx]*x[x_idx] - x[y_idx]*x[y_idx]*W[i]);
    '''</span><span class="token punctuation">,</span>
    name<span class="token operator">=</span><span class="token string">'kernel'</span><span class="token punctuation">)</span>

<span class="token comment"># 変数</span>
T <span class="token operator">=</span> <span class="token number">500</span>        <span class="token comment"># 入力時系列の長さ</span>
N_x <span class="token operator">=</span> <span class="token number">200</span>      <span class="token comment"># 中間層の数</span>
N_in <span class="token operator">=</span> <span class="token number">1</span>       <span class="token comment"># 入力層の数</span>
N_out <span class="token operator">=</span> <span class="token number">1</span>      <span class="token comment"># 出力層の数</span>
activation_func <span class="token operator">=</span> cp<span class="token punctuation">.</span>tanh   <span class="token comment"># 活性化関数</span>
learning_rate <span class="token operator">=</span> <span class="token number">0.000001</span>   <span class="token comment"># 可塑性の学習率</span>
cp<span class="token punctuation">.</span>seed <span class="token operator">=</span> cp<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span>seed<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>

<span class="token comment"># 入力時系列データ</span>
U <span class="token operator">=</span> cp<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>T<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>
train_len <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>U<span class="token punctuation">)</span>

<span class="token comment"># 初期化</span>
Win <span class="token operator">=</span> cp<span class="token punctuation">.</span>random<span class="token punctuation">.</span>uniform<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token punctuation">(</span>N_x<span class="token punctuation">,</span> N_in<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># 入力結合重み行列</span>
x <span class="token operator">=</span> cp<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>N_x<span class="token punctuation">)</span> <span class="token comment"># ニューロンの状態ベクトル</span>
W <span class="token operator">=</span> cp<span class="token punctuation">.</span>random<span class="token punctuation">.</span>uniform<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token punctuation">(</span>N_x<span class="token punctuation">,</span> N_x<span class="token punctuation">)</span><span class="token punctuation">)</span>　<span class="token comment"># 中間層結合重み行列</span>

W_new <span class="token operator">=</span> cp<span class="token punctuation">.</span>zeros_like<span class="token punctuation">(</span>W<span class="token punctuation">)</span> <span class="token comment"># kernelのための入れ物</span>

<span class="token keyword keyword-for">for</span> n <span class="token keyword keyword-in">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>train_len<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># ニューロン状態の更新</span>
    x_in <span class="token operator">=</span> cp<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>Win<span class="token punctuation">,</span> U<span class="token punctuation">[</span>n<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment"># 入力の読み込み</span>
    x <span class="token operator">=</span> x <span class="token operator">+</span> activation_func<span class="token punctuation">(</span>cp<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>W<span class="token punctuation">,</span> x<span class="token punctuation">)</span> <span class="token operator">+</span> x_in<span class="token punctuation">)</span> <span class="token comment"># ニューロン更新</span>
        
    <span class="token comment"># リザバー結合重み行列の更新</span>
    W <span class="token operator">+=</span> kernel<span class="token punctuation">(</span>W<span class="token punctuation">,</span>x<span class="token punctuation">,</span>W<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> learning_rate<span class="token punctuation">,</span> W_new<span class="token punctuation">,</span> size<span class="token operator">=</span><span class="token punctuation">(</span>W<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">*</span> W<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># 引数に出力も追加</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></details>
<p>のようになります．</p>
<h4 class="mume-header" id="%E7%A2%BA%E8%AA%8D">確認</h4>

<p>不安になったので，一応numpyの実装と同じ挙動なのかを確認します．NumpyとCupyはrandom関数のseedが異なる値になるようなので，</p>
<ul>
<li>numpyで計算した結果</li>
<li>numpyで生成した配列をcpに変換してから計算した結果<br>
が等しいかどうかを確認します．</li>
</ul>
<details><summary>Numpy</summary>
<pre data-role="codeBlock" data-info="Python{.line-numbers}" class="language-python line-numbers"><span class="token comment"># 変数</span>
T <span class="token operator">=</span> <span class="token number">500</span>        <span class="token comment"># 入力時系列の長さ</span>
N_x <span class="token operator">=</span> <span class="token number">200</span>      <span class="token comment"># 中間層の数</span>
N_in <span class="token operator">=</span> <span class="token number">1</span>       <span class="token comment"># 入力層の数</span>
N_out <span class="token operator">=</span> <span class="token number">1</span>      <span class="token comment"># 出力層の数</span>
activation_func <span class="token operator">=</span> np<span class="token punctuation">.</span>tanh   <span class="token comment"># 活性化関数</span>
learning_rate <span class="token operator">=</span> <span class="token number">0.000001</span>   <span class="token comment"># 可塑性の学習率</span>
np<span class="token punctuation">.</span>seed <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span>seed<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>

<span class="token comment"># 入力時系列データ</span>
U <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>T<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>

<span class="token comment"># 入力から中間層への結合重みの初期化</span>
Win <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>uniform<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token punctuation">(</span>N_x<span class="token punctuation">,</span> N_in<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># 中間層の状態ベクトルの初期化</span>
x <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>N_x<span class="token punctuation">)</span>
W <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>uniform<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token punctuation">(</span>N_x<span class="token punctuation">,</span> N_x<span class="token punctuation">)</span><span class="token punctuation">)</span>

train_len <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>U<span class="token punctuation">)</span>

<span class="token comment"># 時間発展</span>
<span class="token keyword keyword-for">for</span> n <span class="token keyword keyword-in">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>train_len<span class="token punctuation">)</span><span class="token punctuation">:</span>
    x_in <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>Win<span class="token punctuation">,</span> U<span class="token punctuation">[</span>n<span class="token punctuation">]</span><span class="token punctuation">)</span>
    x <span class="token operator">=</span> x <span class="token operator">+</span> activation_func<span class="token punctuation">(</span>np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>W<span class="token punctuation">,</span> x<span class="token punctuation">)</span> <span class="token operator">+</span> x_in<span class="token punctuation">)</span>
        
    <span class="token comment"># リザバー結合重み行列の更新</span>
    <span class="token keyword keyword-for">for</span> post_neuron <span class="token keyword keyword-in">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>N_x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        W<span class="token punctuation">[</span>post_neuron<span class="token punctuation">]</span> <span class="token operator">+=</span> learning_rate <span class="token operator">*</span> <span class="token punctuation">(</span>x<span class="token punctuation">[</span>post_neuron<span class="token punctuation">]</span> <span class="token operator">*</span> x         <span class="token operator">-</span> np<span class="token punctuation">.</span>square<span class="token punctuation">(</span>x<span class="token punctuation">[</span>post_neuron<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">*</span> W<span class="token punctuation">[</span>post_neuron<span class="token punctuation">]</span><span class="token punctuation">)</span>
        
    <span class="token comment"># リザバー結合重み行列の更新(for 書き下し)</span>
    <span class="token comment">#for post_neuron in range(N_x):</span>
    <span class="token comment">#    for pre_neuron in range(N_x):</span>
    <span class="token comment">#        W2[post_neuron, pre_neuron] += learning_rate * (x[post_neuron] * x[pre_neuron]         - np.square(x[post_neuron]) * W2[post_neuron, pre_neuron])</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></details>
<center><img src="../figures/numpy.png" width="80%"></center>
<details><summary>Numpy -&gt; Cupy</summary>
<pre data-role="codeBlock" data-info="Python{.line-numbers}" class="language-python line-numbers">kernel <span class="token operator">=</span> cp<span class="token punctuation">.</span>ElementwiseKernel<span class="token punctuation">(</span>
    in_params <span class="token operator">=</span> <span class="token string">'raw float64 W, raw float64 x, int16 width, float64 learning_rate'</span><span class="token punctuation">,</span>
    out_params <span class="token operator">=</span> <span class="token string">'raw float64 W_new'</span><span class="token punctuation">,</span>
    operation<span class="token operator">=</span>\
    <span class="token triple-quoted-string string">'''
    int x_idx = i%width; 
    int y_idx = i/width;
    
    W_new[i] = learning_rate * (x[y_idx]*x[x_idx] - x[y_idx]*x[y_idx]*W[i]);
    '''</span><span class="token punctuation">,</span>
    name<span class="token operator">=</span><span class="token string">'kernel'</span><span class="token punctuation">)</span>

<span class="token comment"># 変数</span>
T <span class="token operator">=</span> <span class="token number">500</span>        <span class="token comment"># 入力時系列の長さ</span>
N_x <span class="token operator">=</span> <span class="token number">200</span>      <span class="token comment"># 中間層の数</span>
N_in <span class="token operator">=</span> <span class="token number">1</span>       <span class="token comment"># 入力層の数</span>
N_out <span class="token operator">=</span> <span class="token number">1</span>      <span class="token comment"># 出力層の数</span>
activation_func <span class="token operator">=</span> cp<span class="token punctuation">.</span>tanh   <span class="token comment"># 活性化関数</span>
learning_rate <span class="token operator">=</span> <span class="token number">0.000001</span>   <span class="token comment"># 可塑性の学習率</span>
np<span class="token punctuation">.</span>seed <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span>seed<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>

<span class="token comment"># 入力時系列データ</span>
U <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>T<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>
U <span class="token operator">=</span> cp<span class="token punctuation">.</span>asarray<span class="token punctuation">(</span>U<span class="token punctuation">)</span>

<span class="token comment"># 入力から中間層への結合重みの初期化</span>
Win <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>uniform<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token punctuation">(</span>N_x<span class="token punctuation">,</span> N_in<span class="token punctuation">)</span><span class="token punctuation">)</span>
Win <span class="token operator">=</span> cp<span class="token punctuation">.</span>asarray<span class="token punctuation">(</span>Win<span class="token punctuation">)</span>

<span class="token comment"># 中間層の状態ベクトルの初期化</span>
x <span class="token operator">=</span> cp<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>N_x<span class="token punctuation">)</span>
W <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>uniform<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token punctuation">(</span>N_x<span class="token punctuation">,</span> N_x<span class="token punctuation">)</span><span class="token punctuation">)</span>
W <span class="token operator">=</span> cp<span class="token punctuation">.</span>asarray<span class="token punctuation">(</span>W<span class="token punctuation">)</span>

train_len <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>U<span class="token punctuation">)</span>

W_new <span class="token operator">=</span> cp<span class="token punctuation">.</span>zeros_like<span class="token punctuation">(</span>W<span class="token punctuation">)</span>


<span class="token keyword keyword-for">for</span> n <span class="token keyword keyword-in">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>train_len<span class="token punctuation">)</span><span class="token punctuation">:</span>
    x_in <span class="token operator">=</span> cp<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>Win<span class="token punctuation">,</span> U<span class="token punctuation">[</span>n<span class="token punctuation">]</span><span class="token punctuation">)</span>
    x <span class="token operator">=</span> x                  <span class="token operator">+</span> activation_func<span class="token punctuation">(</span>cp<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>W<span class="token punctuation">,</span> x<span class="token punctuation">)</span>                  <span class="token operator">+</span> x_in<span class="token punctuation">)</span>
        
    <span class="token comment"># リザバー結合重み行列の更新</span>
    W <span class="token operator">+=</span> kernel<span class="token punctuation">(</span>W<span class="token punctuation">,</span>x<span class="token punctuation">,</span>W<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> learning_rate<span class="token punctuation">,</span> W_new<span class="token punctuation">,</span> size<span class="token operator">=</span><span class="token punctuation">(</span>W<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">*</span> W<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># 引数に出力も追加</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></details>
<center><img src="../figures/numcp.png" width="80%"></center>
<p>一致しています．無事にCPUのプログラムをGPUに変換できています．</p>
<h4 class="mume-header" id="%E9%80%9F%E5%BA%A6%E6%AF%94%E8%BC%83">速度比較</h4>

<p>結果，どれだけ早くなるのかを確認します．</p>
<pre data-role="codeBlock" data-info="Python{.line-numbers}" class="language-python line-numbers"><span class="token keyword keyword-import">import</span> tabulate

<span class="token comment"># N ごとの実行時間の差</span>
T <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">500</span><span class="token punctuation">,</span><span class="token number">5000</span><span class="token punctuation">,</span><span class="token number">44100</span><span class="token punctuation">]</span>
times_cpu <span class="token operator">=</span> np<span class="token punctuation">.</span>asarray<span class="token punctuation">(</span>times_cpu<span class="token punctuation">)</span>
times_gpu <span class="token operator">=</span> np<span class="token punctuation">.</span>asarray<span class="token punctuation">(</span>times_gpu<span class="token punctuation">)</span>

<span class="token comment"># tabulate を用いてテーブルを作成</span>
table <span class="token operator">=</span> tabulate<span class="token punctuation">.</span>tabulate<span class="token punctuation">(</span>
    <span class="token builtin">zip</span><span class="token punctuation">(</span>T<span class="token punctuation">,</span> times_cpu<span class="token punctuation">,</span> times_gpu<span class="token punctuation">)</span><span class="token punctuation">,</span>
    headers<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'T(length of input)'</span><span class="token punctuation">,</span> <span class="token string">'CPU での実行時間 (sec)'</span><span class="token punctuation">,</span> <span class="token string">'GPU での実行時間 (sec)'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token keyword keyword-print">print</span><span class="token punctuation">(</span>table<span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre><p>まず，入力時系列の長さを変化させていった時のCPU，GPUそれぞれの計算時間を比較します．</p>
<img src="../figures/table1.png">
<p>次に，同様にニューロンの数を変化させて比較します．</p>
<details><summary>code</summary>
<pre data-role="codeBlock" data-info="Python{.line-numbers}" class="language-python line-numbers"><span class="token keyword keyword-import">import</span> tabulate

<span class="token comment"># N ごとの実行時間の差</span>
N <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">200</span><span class="token punctuation">,</span><span class="token number">1000</span><span class="token punctuation">,</span><span class="token number">2000</span><span class="token punctuation">]</span>
times_cpu <span class="token operator">=</span> np<span class="token punctuation">.</span>asarray<span class="token punctuation">(</span>times_cpu<span class="token punctuation">)</span>
times_gpu <span class="token operator">=</span> np<span class="token punctuation">.</span>asarray<span class="token punctuation">(</span>times_gpu<span class="token punctuation">)</span>

<span class="token comment"># tabulate を用いてテーブルを作成</span>
table <span class="token operator">=</span> tabulate<span class="token punctuation">.</span>tabulate<span class="token punctuation">(</span>
    <span class="token builtin">zip</span><span class="token punctuation">(</span>N<span class="token punctuation">,</span> times_cpu<span class="token punctuation">,</span> times_gpu<span class="token punctuation">)</span><span class="token punctuation">,</span>
    headers<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'N(Size of reservoir)'</span><span class="token punctuation">,</span> <span class="token string">'CPU での実行時間 (sec)'</span><span class="token punctuation">,</span> <span class="token string">'GPU での実行時間 (sec)'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token keyword keyword-print">print</span><span class="token punctuation">(</span>table<span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></details>
<img src="../figures/table2.png">
<p>どちらも，GPUを使うことで計算時間が大幅に短縮されているのが確認できました．</p>
<div style="text-align: center;">
<p>【<a href="./simulation.html">シミュレーション</a>】</p>
</div>
      </div>
      
      
    
    
    
    
    
    
  
    </body></html>